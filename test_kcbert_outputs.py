# -*- coding: utf-8 -*-
"""
KcBERT ì¶œë ¥ í•„ë“œ ë¶„ì„ í…ŒìŠ¤íŠ¸
ëª¨ë¸ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” ëª¨ë“  ì •ë³´ í™•ì¸
"""

import sys
import os
import warnings

warnings.filterwarnings('ignore')
os.environ['TRANSFORMERS_VERBOSITY'] = 'error'

if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

import logging
logging.getLogger('transformers').setLevel(logging.ERROR)

import torch
import numpy as np


def test_kcbert_outputs():
    """KcBERT ëª¨ë¸ ì¶œë ¥ ë¶„ì„"""
    print("\n" + "=" * 70)
    print("ğŸ”¬ KcBERT ëª¨ë¸ ì¶œë ¥ í•„ë“œ ë¶„ì„")
    print("=" * 70 + "\n")
    
    # ëª¨ë¸ ë¡œë“œ
    print("ğŸ“¥ KcBERT ëª¨ë¸ ë¡œë”© ì¤‘...")
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
    
    tokenizer = AutoTokenizer.from_pretrained(
        "beomi/kcbert-base",
        cache_dir="./models/kcbert"
    )
    
    model = AutoModelForSequenceClassification.from_pretrained(
        "beomi/kcbert-base",
        cache_dir="./models/kcbert",
        num_labels=2,
        ignore_mismatched_sizes=True
    )
    
    model.eval()
    print("âœ… ë¡œë”© ì™„ë£Œ\n")
    
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
    test_text = "ì§„ì§œ ë„ˆë¬´ í™”ë‚˜ë„¤ìš”. ì´ê²Œ ë­í•˜ëŠ” ì§“ì´ì•¼!"
    
    print("â”€" * 70)
    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸: \"{test_text}\"")
    print("â”€" * 70)
    print()
    
    # í† í°í™”
    inputs = tokenizer(
        test_text,
        return_tensors="pt",
        max_length=300,
        padding="max_length",
        truncation=True
    )
    
    print("ğŸ“Š 1. ê¸°ë³¸ ì¶œë ¥ (í˜„ì¬ ì‚¬ìš© ì¤‘)")
    print("â”€" * 70)
    
    with torch.no_grad():
        # ê¸°ë³¸ ì¶œë ¥
        outputs = model(**inputs)
        
        # Logits (ì›ì‹œ ì¶œë ¥ê°’)
        logits = outputs.logits
        print(f"  â€¢ logits: {logits}")
        print(f"    - shape: {logits.shape}")
        print(f"    - ì •ìƒ í´ë˜ìŠ¤ ìŠ¤ì½”ì–´: {logits[0][0].item():.4f}")
        print(f"    - ìš•ì„¤ í´ë˜ìŠ¤ ìŠ¤ì½”ì–´: {logits[0][1].item():.4f}")
        print()
        
        # Softmax í™•ë¥ 
        probabilities = torch.nn.functional.softmax(logits, dim=-1)
        normal_prob = probabilities[0][0].item()
        abusive_prob = probabilities[0][1].item()
        confidence = torch.max(probabilities).item()
        
        print(f"  â€¢ probabilities (softmax ì ìš© í›„):")
        print(f"    - ì •ìƒ í™•ë¥ : {normal_prob:.4f} ({normal_prob*100:.2f}%)")
        print(f"    - ìš•ì„¤ í™•ë¥ : {abusive_prob:.4f} ({abusive_prob*100:.2f}%)")
        print(f"    - ì‹ ë¢°ë„ (ìµœëŒ€ê°’): {confidence:.4f} ({confidence*100:.2f}%)")
        print()
        
        # ì˜ˆì¸¡ í´ë˜ìŠ¤
        predicted_class = torch.argmax(logits, dim=-1).item()
        print(f"  â€¢ predicted_class: {predicted_class}")
        print(f"    - 0: ì •ìƒ, 1: ìš•ì„¤")
        print()
    
    print()
    print("ğŸ“Š 2. ì¶”ê°€ ì¶œë ¥ (output_hidden_states=True)")
    print("â”€" * 70)
    
    with torch.no_grad():
        # Hidden states í¬í•¨
        outputs = model(**inputs, output_hidden_states=True)
        
        hidden_states = outputs.hidden_states
        print(f"  â€¢ hidden_states: ì „ì²´ ë ˆì´ì–´ì˜ ì€ë‹‰ ìƒíƒœ")
        print(f"    - ë ˆì´ì–´ ìˆ˜: {len(hidden_states)}ê°œ")
        print(f"    - ê° ë ˆì´ì–´ shape: {hidden_states[0].shape}")
        print(f"    - (batch_size, sequence_length, hidden_size)")
        print()
        
        # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ [CLS] í† í° ì„ë² ë”©
        last_hidden_state = hidden_states[-1]
        cls_embedding = last_hidden_state[0][0]  # [CLS] í† í°
        
        print(f"  â€¢ [CLS] í† í° ì„ë² ë”© (ë¬¸ì¥ ì „ì²´ í‘œí˜„):")
        print(f"    - shape: {cls_embedding.shape}")
        print(f"    - ì˜ˆì‹œ ê°’ (ì²˜ìŒ 5ê°œ): {cls_embedding[:5].tolist()}")
        print(f"    - ì´ ë²¡í„°ë¡œ ë¬¸ì¥ ìœ ì‚¬ë„ ê³„ì‚° ê°€ëŠ¥")
        print()
    
    print()
    print("ğŸ“Š 3. ì¶”ê°€ ì¶œë ¥ (output_attentions=True)")
    print("â”€" * 70)
    
    with torch.no_grad():
        # Attention weights í¬í•¨
        outputs = model(**inputs, output_attentions=True)
        
        attentions = outputs.attentions
        print(f"  â€¢ attentions: ê° ë ˆì´ì–´ì˜ ì–´í…ì…˜ ê°€ì¤‘ì¹˜")
        print(f"    - ë ˆì´ì–´ ìˆ˜: {len(attentions)}ê°œ")
        print(f"    - ê° ë ˆì´ì–´ shape: {attentions[0].shape}")
        print(f"    - (batch_size, num_heads, seq_length, seq_length)")
        print()
        
        # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ í‰ê·  ì–´í…ì…˜
        last_attention = attentions[-1]
        avg_attention = last_attention.mean(dim=1)[0]  # í—¤ë“œë“¤ì˜ í‰ê· 
        
        print(f"  â€¢ ë§ˆì§€ë§‰ ë ˆì´ì–´ í‰ê·  ì–´í…ì…˜:")
        print(f"    - shape: {avg_attention.shape}")
        print(f"    - [CLS] í† í°ì´ ë‹¤ë¥¸ í† í°ì— ì£¼ëª©í•˜ëŠ” ì •ë„")
        print()
        
        # í† í°ë³„ ì–´í…ì…˜ ì ìˆ˜
        tokens = tokenizer.tokenize(test_text)
        cls_attention_to_tokens = avg_attention[0][1:len(tokens)+1]
        
        print(f"  â€¢ í† í°ë³„ ì–´í…ì…˜ ì ìˆ˜ (ì¤‘ìš”ë„):")
        for token, attn_score in zip(tokens[:10], cls_attention_to_tokens[:10]):
            print(f"    - '{token}': {attn_score.item():.4f}")
        print()
    
    print()
    print("ğŸ“Š 4. í˜„ì¬ ë°˜í™˜ ì¤‘ì¸ í•„ë“œ")
    print("â”€" * 70)
    
    current_fields = {
        "text": "ì…ë ¥ í…ìŠ¤íŠ¸",
        "is_abusive": "ìš•ì„¤ ì—¬ë¶€ (ë¶ˆë¦°)",
        "confidence": "ì‹ ë¢°ë„ (0~1)",
        "abusive_score": "ìµœì¢… ê³µê²©ì„± ì ìˆ˜ (0~1)",
        "model_score": "ëª¨ë¸ ì›ì‹œ ì ìˆ˜ (0~1)",
        "rule_score": "ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ (0~1)",
        "threshold": "ê°ì§€ ì„ê³„ê°’",
        "processing_time": "ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)"
    }
    
    for field, desc in current_fields.items():
        print(f"  âœ“ {field:20s}: {desc}")
    
    print()
    print()
    print("ğŸ“Š 5. ì¶”ê°€ ê°€ëŠ¥í•œ í•„ë“œ")
    print("â”€" * 70)
    
    additional_fields = {
        # ê¸°ë³¸ ëª¨ë¸ ì¶œë ¥
        "logits": {
            "ì„¤ëª…": "ì›ì‹œ ì¶œë ¥ê°’ (softmax ì „)",
            "ìš©ë„": "ë””ë²„ê¹…, ì»¤ìŠ¤í…€ í›„ì²˜ë¦¬",
            "í¬ê¸°": "ì‘ìŒ",
            "ì¶”ì²œ": "â­"
        },
        "class_probabilities": {
            "ì„¤ëª…": "ê° í´ë˜ìŠ¤ë³„ í™•ë¥  [ì •ìƒ, ìš•ì„¤]",
            "ìš©ë„": "ìƒì„¸ í™•ë¥  ë¶„í¬ í™•ì¸",
            "í¬ê¸°": "ì‘ìŒ",
            "ì¶”ì²œ": "â­â­â­"
        },
        "predicted_class": {
            "ì„¤ëª…": "ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ (0 ë˜ëŠ” 1)",
            "ìš©ë„": "ê°„ë‹¨í•œ ë¶„ë¥˜ ê²°ê³¼",
            "í¬ê¸°": "ì‘ìŒ",
            "ì¶”ì²œ": "â­â­"
        },
        
        # í† í° ì •ë³´
        "token_count": {
            "ì„¤ëª…": "ì…ë ¥ í† í° ê°œìˆ˜",
            "ìš©ë„": "ê¸¸ì´ ì²´í¬, ì˜ë¦¼ ê°ì§€",
            "í¬ê¸°": "ì‘ìŒ",
            "ì¶”ì²œ": "â­â­â­"
        },
        "tokens": {
            "ì„¤ëª…": "í† í°í™”ëœ ê²°ê³¼",
            "ìš©ë„": "ë””ë²„ê¹…, ë¶„ì„",
            "í¬ê¸°": "ì¤‘ê°„",
            "ì¶”ì²œ": "â­â­"
        },
        "is_truncated": {
            "ì„¤ëª…": "300 í† í° ì´ˆê³¼ë¡œ ì˜ë ¸ëŠ”ì§€ ì—¬ë¶€",
            "ìš©ë„": "ë°ì´í„° ì†ì‹¤ ê°ì§€",
            "í¬ê¸°": "ì‘ìŒ",
            "ì¶”ì²œ": "â­â­â­"
        },
        
        # ê³ ê¸‰ ê¸°ëŠ¥
        "sentence_embedding": {
            "ì„¤ëª…": "[CLS] í† í° ë²¡í„° (768ì°¨ì›)",
            "ìš©ë„": "ë¬¸ì¥ ìœ ì‚¬ë„, í´ëŸ¬ìŠ¤í„°ë§",
            "í¬ê¸°": "ì¤‘ê°„",
            "ì¶”ì²œ": "â­"
        },
        "token_attentions": {
            "ì„¤ëª…": "ê° í† í°ì˜ ì¤‘ìš”ë„ ì ìˆ˜",
            "ìš©ë„": "ì–´ë–¤ ë‹¨ì–´ê°€ ì¤‘ìš”í–ˆëŠ”ì§€ ë¶„ì„",
            "í¬ê¸°": "ì¤‘ê°„",
            "ì¶”ì²œ": "â­â­"
        },
        "hidden_states": {
            "ì„¤ëª…": "ì „ì²´ ë ˆì´ì–´ ì€ë‹‰ ìƒíƒœ",
            "ìš©ë„": "ê³ ê¸‰ NLP ì—°êµ¬",
            "í¬ê¸°": "ë§¤ìš° í¼",
            "ì¶”ì²œ": ""
        },
        "attention_weights": {
            "ì„¤ëª…": "ì „ì²´ ì–´í…ì…˜ ê°€ì¤‘ì¹˜",
            "ìš©ë„": "ì–´í…ì…˜ ì‹œê°í™”, ì—°êµ¬",
            "í¬ê¸°": "ë§¤ìš° í¼",
            "ì¶”ì²œ": ""
        },
        
        # ë¶„ì„ ì •ë³´
        "abusive_words_found": {
            "ì„¤ëª…": "ê°ì§€ëœ ìš•ì„¤ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸",
            "ìš©ë„": "êµ¬ì²´ì ì¸ ë¬¸ì œ ë‹¨ì–´ í™•ì¸",
            "í¬ê¸°": "ì‘ìŒ",
            "ì¶”ì²œ": "â­â­â­"
        },
        "severity_level": {
            "ì„¤ëª…": "ì‹¬ê°ë„ (ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ/ë§¤ìš°ë†’ìŒ)",
            "ìš©ë„": "ë“±ê¸‰ë³„ ë¶„ë¥˜",
            "í¬ê¸°": "ì‘ìŒ",
            "ì¶”ì²œ": "â­â­â­"
        },
        "detection_method": {
            "ì„¤ëª…": "ê°ì§€ ë°©ë²• (ëª¨ë¸/ê·œì¹™/í˜¼í•©)",
            "ìš©ë„": "ê°ì§€ ê·¼ê±° ì¶”ì ",
            "í¬ê¸°": "ì‘ìŒ",
            "ì¶”ì²œ": "â­â­"
        }
    }
    
    for field, info in additional_fields.items():
        print(f"\n  â€¢ {field}")
        print(f"    - ì„¤ëª…: {info['ì„¤ëª…']}")
        print(f"    - ìš©ë„: {info['ìš©ë„']}")
        print(f"    - ë°ì´í„° í¬ê¸°: {info['í¬ê¸°']}")
        print(f"    - ì¶”ì²œë„: {info['ì¶”ì²œ']}")
    
    print()
    print()
    print("ğŸ’¡ ì¶”ì²œ ì¶”ê°€ í•„ë“œ (ì‹¤ìš©ì )")
    print("â”€" * 70)
    
    recommended = [
        "class_probabilities - ì •ìƒ/ìš•ì„¤ ê°ê°ì˜ í™•ë¥ ",
        "token_count - ì…ë ¥ í† í° ê°œìˆ˜",
        "is_truncated - 300 í† í° ì´ˆê³¼ ì—¬ë¶€",
        "abusive_words_found - ê°ì§€ëœ ìš•ì„¤ ë‹¨ì–´ ëª©ë¡",
        "severity_level - ì‹¬ê°ë„ ë“±ê¸‰ (ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ)"
    ]
    
    for i, rec in enumerate(recommended, 1):
        print(f"  {i}. {rec}")
    
    print()
    print()
    print("âš¡ ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­")
    print("â”€" * 70)
    print("  â€¢ hidden_states, attention_weightsëŠ” ë§¤ìš° í° ë°ì´í„°")
    print("  â€¢ ì¼ë°˜ ì‚¬ìš©ì—ëŠ” í•„ìš” ì—†ìŒ (ì—°êµ¬/ì‹œê°í™” ëª©ì )")
    print("  â€¢ ê¸°ë³¸ í•„ë“œ + ì¶”ì²œ í•„ë“œë§Œìœ¼ë¡œë„ ì¶©ë¶„")
    print("  â€¢ í•„ìš”ì‹œ output_hidden_states=Trueë¡œ í™œì„±í™” ê°€ëŠ¥")
    print()
    
    print("=" * 70)
    
    # ì‹¤ì œ ì˜ˆì œ
    print()
    print("ğŸ“ ì‹¤ì œ í™œìš© ì˜ˆì œ")
    print("â”€" * 70)
    print()
    
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probabilities = torch.nn.functional.softmax(logits, dim=-1)
        
        tokens = tokenizer.tokenize(test_text)
        token_count = len(tokens)
        is_truncated = token_count > 300
        
        # ì˜ˆì œ ê²°ê³¼
        example_result = {
            # ê¸°ì¡´ í•„ë“œ
            "text": test_text,
            "is_abusive": True,
            "confidence": 0.89,
            "abusive_score": 0.85,
            "model_score": 0.78,
            "rule_score": 0.95,
            "threshold": 0.5,
            "processing_time": 0.035,
            
            # ì¶”ê°€ ê°€ëŠ¥í•œ í•„ë“œ (ì¶”ì²œ)
            "class_probabilities": {
                "normal": probabilities[0][0].item(),
                "abusive": probabilities[0][1].item()
            },
            "token_count": token_count,
            "is_truncated": is_truncated,
            "abusive_words_found": ["í™”ë‚˜ë„¤ìš”", "ë­í•˜ëŠ” ì§“"],
            "severity_level": "ë†’ìŒ",
            "detection_method": "í˜¼í•©"
        }
        
        import json
        print(json.dumps(example_result, ensure_ascii=False, indent=2))
    
    print()
    print("=" * 70)


if __name__ == "__main__":
    test_kcbert_outputs()
