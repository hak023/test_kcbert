# -*- coding: utf-8 -*-
"""
KcBERT CPU ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
ë…¸íŠ¸ë¶ CPU vs ì„œë²„ CPU ë¹„êµ
"""

import sys
import os
import warnings

warnings.filterwarnings('ignore')
os.environ['TRANSFORMERS_VERBOSITY'] = 'error'

if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

import logging
logging.getLogger('transformers').setLevel(logging.ERROR)

import time
import platform
import psutil
import torch
from pathlib import Path


def get_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘"""
    info = {
        "os": platform.system(),
        "os_version": platform.version(),
        "processor": platform.processor(),
        "cpu_cores_physical": psutil.cpu_count(logical=False),
        "cpu_cores_logical": psutil.cpu_count(logical=True),
        "cpu_freq_current": psutil.cpu_freq().current if psutil.cpu_freq() else "N/A",
        "cpu_freq_max": psutil.cpu_freq().max if psutil.cpu_freq() else "N/A",
        "ram_total_gb": round(psutil.virtual_memory().total / (1024**3), 2),
        "ram_available_gb": round(psutil.virtual_memory().available / (1024**3), 2),
    }
    return info


def benchmark_kcbert():
    """KcBERT ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    print("\n" + "=" * 70)
    print("âš¡ KcBERT CPU ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
    print("=" * 70 + "\n")
    
    # ì‹œìŠ¤í…œ ì •ë³´
    print("ğŸ“Š í˜„ì¬ ì‹œìŠ¤í…œ ì •ë³´")
    print("â”€" * 70)
    sys_info = get_system_info()
    print(f"  â€¢ OS: {sys_info['os']} {sys_info['os_version']}")
    print(f"  â€¢ CPU: {sys_info['processor']}")
    print(f"  â€¢ ë¬¼ë¦¬ ì½”ì–´: {sys_info['cpu_cores_physical']}ê°œ")
    print(f"  â€¢ ë…¼ë¦¬ ì½”ì–´: {sys_info['cpu_cores_logical']}ê°œ")
    print(f"  â€¢ CPU í˜„ì¬ í´ëŸ­: {sys_info['cpu_freq_current']} MHz")
    print(f"  â€¢ CPU ìµœëŒ€ í´ëŸ­: {sys_info['cpu_freq_max']} MHz")
    print(f"  â€¢ ì „ì²´ RAM: {sys_info['ram_total_gb']} GB")
    print(f"  â€¢ ì‚¬ìš© ê°€ëŠ¥ RAM: {sys_info['ram_available_gb']} GB")
    print(f"  â€¢ PyTorch: {torch.__version__}")
    print(f"  â€¢ ë””ë°”ì´ìŠ¤: CPU (GPU ë¯¸ì‚¬ìš©)")
    print()
    
    # ëª¨ë¸ ë¡œë“œ
    print("ğŸ“¥ KcBERT ëª¨ë¸ ë¡œë”© ì¤‘...")
    load_start = time.time()
    
    # stderr ì–µì œ
    class SuppressStderr:
        def __enter__(self):
            self.original_stderr = sys.stderr
            sys.stderr = open(os.devnull, 'w')
            return self
        
        def __exit__(self, exc_type, exc_val, exc_tb):
            sys.stderr.close()
            sys.stderr = self.original_stderr
    
    with SuppressStderr():
        from src.detector import AbusiveDetector
        detector = AbusiveDetector()
        detector.load_model()
    
    load_time = time.time() - load_start
    print(f"âœ… ë¡œë”© ì™„ë£Œ (ì†Œìš” ì‹œê°„: {load_time:.2f}ì´ˆ)")
    print()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    samples_dir = Path("data/samples")
    test_files = list(samples_dir.glob("*.txt"))
    
    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_files)}ê°œ íŒŒì¼")
    print("â”€" * 70)
    
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ì¤€ë¹„
    test_cases = []
    for file_path in test_files:
        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read()
            test_cases.append({
                "name": file_path.stem,
                "text": text,
                "length": len(text)
            })
    
    for case in test_cases:
        print(f"  â€¢ {case['name']:20s}: {case['length']:4d}ì")
    print()
    
    # ì›Œë°ì—… (ì²« ì‹¤í–‰ì€ ëŠë¦´ ìˆ˜ ìˆìŒ)
    print("ğŸ”¥ ì›Œë°ì—… ì¤‘...")
    _ = detector.predict(test_cases[0]['text'])
    print("âœ… ì›Œë°ì—… ì™„ë£Œ")
    print()
    
    # ë‹¨ì¼ ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬
    print("â”€" * 70)
    print("â±ï¸  1. ë‹¨ì¼ ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬ (ê° íŒŒì¼ 1íšŒ)")
    print("â”€" * 70)
    
    single_times = []
    for case in test_cases:
        start = time.time()
        result = detector.predict(case['text'])
        elapsed = time.time() - start
        single_times.append(elapsed)
        
        print(f"  â€¢ {case['name']:20s}: {elapsed*1000:6.2f}ms "
              f"(ì ìˆ˜: {result['abusive_score']:.3f})")
    
    avg_single = sum(single_times) / len(single_times)
    print(f"\n  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_single*1000:.2f}ms")
    print()
    
    # ë°˜ë³µ ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬
    print("â”€" * 70)
    print("â±ï¸  2. ë°˜ë³µ ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬ (100íšŒ)")
    print("â”€" * 70)
    
    test_text = test_cases[0]['text']
    iterations = 100
    
    print(f"  í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸: {test_cases[0]['name']}")
    print(f"  ë°˜ë³µ íšŸìˆ˜: {iterations}íšŒ")
    print()
    
    # CPU ì‚¬ìš©ë¥  ì¸¡ì • ì‹œì‘
    cpu_before = psutil.cpu_percent(interval=0.1)
    
    start = time.time()
    for i in range(iterations):
        _ = detector.predict(test_text)
        if (i + 1) % 20 == 0:
            print(f"  ì§„í–‰: {i+1}/{iterations}íšŒ...")
    elapsed = time.time() - start
    
    # CPU ì‚¬ìš©ë¥  ì¸¡ì •
    cpu_after = psutil.cpu_percent(interval=0.1)
    
    avg_iter = elapsed / iterations
    throughput = iterations / elapsed
    
    print()
    print(f"  âœ“ ì´ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
    print(f"  âœ“ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_iter*1000:.2f}ms")
    print(f"  âœ“ ì²˜ë¦¬ëŸ‰ (TPS): {throughput:.2f}ê±´/ì´ˆ")
    print(f"  âœ“ CPU ì‚¬ìš©ë¥ : {cpu_after:.1f}%")
    print()
    
    # ë°°ì¹˜ í¬ê¸°ë³„ ì²˜ë¦¬ëŸ‰
    print("â”€" * 70)
    print("â±ï¸  3. ë°°ì¹˜ í¬ê¸°ë³„ ì²˜ë¦¬ëŸ‰")
    print("â”€" * 70)
    
    batch_sizes = [1, 5, 10, 20]
    batch_results = []
    
    for batch_size in batch_sizes:
        texts = [test_text] * batch_size
        
        start = time.time()
        for text in texts:
            _ = detector.predict(text)
        elapsed = time.time() - start
        
        avg_per_item = elapsed / batch_size
        tps = batch_size / elapsed
        
        batch_results.append({
            "size": batch_size,
            "total_time": elapsed,
            "avg_time": avg_per_item,
            "tps": tps
        })
        
        print(f"  â€¢ ë°°ì¹˜ í¬ê¸° {batch_size:2d}: "
              f"ì´ {elapsed:.3f}ì´ˆ, "
              f"í‰ê·  {avg_per_item*1000:.2f}ms, "
              f"{tps:.2f}ê±´/ì´ˆ")
    
    print()
    
    # ê²°ê³¼ ìš”ì•½
    print("=" * 70)
    print("ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½")
    print("=" * 70)
    print()
    
    print(f"  ğŸ–¥ï¸  í˜„ì¬ ë…¸íŠ¸ë¶ CPU")
    print(f"  â”œâ”€ í”„ë¡œì„¸ì„œ: {sys_info['processor']}")
    print(f"  â”œâ”€ ì½”ì–´: {sys_info['cpu_cores_physical']}ê°œ (ë…¼ë¦¬ {sys_info['cpu_cores_logical']}ê°œ)")
    print(f"  â”œâ”€ í´ëŸ­: {sys_info['cpu_freq_max']} MHz")
    print(f"  â”œâ”€ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_single*1000:.2f}ms")
    print(f"  â””â”€ ì²˜ë¦¬ëŸ‰: {throughput:.2f}ê±´/ì´ˆ")
    print()
    
    # ì„œë²„ CPU ë¹„êµ ì¶”ì •
    print("â”€" * 70)
    print("ğŸ’» ì„œë²„ CPUì™€ì˜ ë¹„êµ (ì¶”ì •)")
    print("â”€" * 70)
    print()
    
    # ì¼ë°˜ì ì¸ ì„œë²„ CPU ì„±ëŠ¥ ë°°ìˆ˜
    server_cpus = [
        {
            "name": "Intel Xeon Gold 6248R",
            "cores": 24,
            "threads": 48,
            "base_clock": 3.0,
            "turbo_clock": 4.0,
            "year": 2020,
            "performance_factor": 2.5,  # ë…¸íŠ¸ë¶ ëŒ€ë¹„
            "notes": "ì¤‘ê¸‰ ì„œë²„ CPU"
        },
        {
            "name": "AMD EPYC 7543",
            "cores": 32,
            "threads": 64,
            "base_clock": 2.8,
            "turbo_clock": 3.7,
            "year": 2021,
            "performance_factor": 3.0,  # ë…¸íŠ¸ë¶ ëŒ€ë¹„
            "notes": "ê³ ê¸‰ ì„œë²„ CPU"
        },
        {
            "name": "Intel Xeon E5-2680 v4",
            "cores": 14,
            "threads": 28,
            "base_clock": 2.4,
            "turbo_clock": 3.3,
            "year": 2016,
            "performance_factor": 1.8,  # ë…¸íŠ¸ë¶ ëŒ€ë¹„
            "notes": "êµ¬í˜• ì„œë²„ CPU"
        },
        {
            "name": "AMD EPYC 9654",
            "cores": 96,
            "threads": 192,
            "base_clock": 2.4,
            "turbo_clock": 3.7,
            "year": 2022,
            "performance_factor": 4.0,  # ë…¸íŠ¸ë¶ ëŒ€ë¹„
            "notes": "ìµœì‹  ê³ ì„±ëŠ¥ ì„œë²„ CPU"
        }
    ]
    
    for cpu in server_cpus:
        est_time = avg_single / cpu['performance_factor']
        est_tps = throughput * cpu['performance_factor']
        speedup = cpu['performance_factor']
        
        print(f"  ğŸ–¥ï¸  {cpu['name']}")
        print(f"  â”œâ”€ ì‚¬ì–‘: {cpu['cores']}ì½”ì–´/{cpu['threads']}ì“°ë ˆë“œ, "
              f"{cpu['base_clock']}GHz (ìµœëŒ€ {cpu['turbo_clock']}GHz)")
        print(f"  â”œâ”€ ì„±ëŠ¥: ë…¸íŠ¸ë¶ ëŒ€ë¹„ ì•½ {speedup:.1f}ë°°")
        print(f"  â”œâ”€ ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {est_time*1000:.2f}ms (í˜„ì¬: {avg_single*1000:.2f}ms)")
        print(f"  â”œâ”€ ì˜ˆìƒ ì²˜ë¦¬ëŸ‰: {est_tps:.2f}ê±´/ì´ˆ (í˜„ì¬: {throughput:.2f}ê±´/ì´ˆ)")
        print(f"  â””â”€ {cpu['notes']} ({cpu['year']}ë…„)")
        print()
    
    print("â”€" * 70)
    print()
    
    # ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤
    print("ğŸ’¡ ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ")
    print("â”€" * 70)
    print()
    
    scenarios = [
        {"name": "1,000ê±´ ì¼ê´„ ì²˜ë¦¬", "count": 1000},
        {"name": "10,000ê±´ ì¼ê´„ ì²˜ë¦¬", "count": 10000},
        {"name": "100,000ê±´ ì¼ê´„ ì²˜ë¦¬", "count": 100000},
        {"name": "ì‹¤ì‹œê°„ ì²˜ë¦¬ (ì´ˆë‹¹ 10ê±´)", "count": 10, "unit": "ì´ˆ"},
        {"name": "ì‹¤ì‹œê°„ ì²˜ë¦¬ (ì´ˆë‹¹ 100ê±´)", "count": 100, "unit": "ì´ˆ"},
    ]
    
    print(f"{'ì‹œë‚˜ë¦¬ì˜¤':<25s} {'í˜„ì¬ ë…¸íŠ¸ë¶':<15s} {'ì„œë²„ (2.5ë°°)':<15s} {'ì„œë²„ (3ë°°)':<15s}")
    print("â”€" * 70)
    
    for scenario in scenarios:
        count = scenario['count']
        
        if scenario.get('unit') == 'ì´ˆ':
            # ì‹¤ì‹œê°„ ì²˜ë¦¬ - TPS ê¸°ì¤€
            current = "ê°€ëŠ¥" if throughput >= count else "ë¶ˆê°€ëŠ¥"
            server_25x = "ê°€ëŠ¥" if throughput * 2.5 >= count else "ë¶ˆê°€ëŠ¥"
            server_3x = "ê°€ëŠ¥" if throughput * 3.0 >= count else "ë¶ˆê°€ëŠ¥"
            
            print(f"{scenario['name']:<25s} {current:<15s} {server_25x:<15s} {server_3x:<15s}")
        else:
            # ë°°ì¹˜ ì²˜ë¦¬ - ì‹œê°„ ê¸°ì¤€
            current_time = count * avg_single
            server_25x_time = count * avg_single / 2.5
            server_3x_time = count * avg_single / 3.0
            
            def format_time(seconds):
                if seconds < 60:
                    return f"{seconds:.1f}ì´ˆ"
                elif seconds < 3600:
                    return f"{seconds/60:.1f}ë¶„"
                else:
                    return f"{seconds/3600:.1f}ì‹œê°„"
            
            print(f"{scenario['name']:<25s} "
                  f"{format_time(current_time):<15s} "
                  f"{format_time(server_25x_time):<15s} "
                  f"{format_time(server_3x_time):<15s}")
    
    print()
    
    # ì„±ëŠ¥ í–¥ìƒ íŒ
    print("=" * 70)
    print("ğŸš€ ì„±ëŠ¥ í–¥ìƒ íŒ")
    print("=" * 70)
    print()
    
    tips = [
        ("ì„œë²„ CPU ì„ íƒ", "ì½”ì–´ ìˆ˜ë³´ë‹¤ ë‹¨ì¼ ì½”ì–´ ì„±ëŠ¥ì´ ì¤‘ìš” (BERTëŠ” ë‹¨ì¼ ìŠ¤ë ˆë“œ)"),
        ("ë°°ì¹˜ ì²˜ë¦¬", "ê°€ëŠ¥í•˜ë©´ ì—¬ëŸ¬ ê±´ì„ ëª¨ì•„ì„œ ì²˜ë¦¬ (ì˜¤ë²„í—¤ë“œ ê°ì†Œ)"),
        ("ë©€í‹° í”„ë¡œì„¸ìŠ¤", "ì—¬ëŸ¬ í”„ë¡œì„¸ìŠ¤ë¡œ ë³‘ë ¬ ì²˜ë¦¬ (ì½”ì–´ ìˆ˜ë§Œí¼ í–¥ìƒ)"),
        ("ëª¨ë¸ ìµœì í™”", "ONNX Runtime ì‚¬ìš© ì‹œ 1.5~2ë°° ë¹¨ë¼ì§"),
        ("ì–‘ìí™”", "INT8 ì–‘ìí™” ì‹œ 2~4ë°° ë¹¨ë¼ì§€ê³  ë©”ëª¨ë¦¬ ì ˆì•½"),
        ("GPU ì‚¬ìš©", "ì„œë²„ì— GPU ìˆìœ¼ë©´ 10~20ë°° ë¹¨ë¼ì§"),
    ]
    
    for i, (title, desc) in enumerate(tips, 1):
        print(f"  {i}. {title}")
        print(f"     â†’ {desc}")
        print()
    
    print("=" * 70)
    
    # ìµœì¢… ê²°ë¡ 
    print()
    print("ğŸ“Œ ê²°ë¡ ")
    print("â”€" * 70)
    print()
    print(f"  í˜„ì¬ ë…¸íŠ¸ë¶ CPU: {avg_single*1000:.2f}ms/ê±´, {throughput:.2f}ê±´/ì´ˆ")
    print(f"  ì¤‘ê¸‰ ì„œë²„ CPU (ì˜ˆìƒ): {avg_single/2.5*1000:.2f}ms/ê±´, {throughput*2.5:.2f}ê±´/ì´ˆ")
    print(f"  ê³ ê¸‰ ì„œë²„ CPU (ì˜ˆìƒ): {avg_single/3.0*1000:.2f}ms/ê±´, {throughput*3.0:.2f}ê±´/ì´ˆ")
    print()
    print(f"  â†’ ì„œë²„ CPU ì‚¬ìš© ì‹œ ì•½ 2~4ë°° ë¹ ë¥¸ ì²˜ë¦¬ ê°€ëŠ¥")
    print(f"  â†’ GPU ì‚¬ìš© ì‹œ 10~20ë°° ë” ë¹ ë¥¸ ì²˜ë¦¬ ê°€ëŠ¥")
    print()
    print("=" * 70)
    
    return {
        "system_info": sys_info,
        "avg_time_ms": avg_single * 1000,
        "throughput_tps": throughput,
        "load_time": load_time
    }


if __name__ == "__main__":
    try:
        results = benchmark_kcbert()
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
