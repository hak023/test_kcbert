# KcBERT 욕설/폭언 감지 시스템 정확도 개선 방안

## 📊 현재 시스템 분석

### 현재 성능 (테스트 결과)

| 파일 | 실제 | 예측 | 점수 | 정확도 |
|-----|------|------|------|--------|
| abusive_call.txt | 욕설 | ⚠️ 욕설 | 0.9500 | ✅ 정답 |
| complaint_call.txt | 정상 | ⚠️ 욕설 | 0.6000 | ❌ 오탐 |
| mixed_call.txt | 경계 | ✅ 정상 | 0.1681 | ✅ 정답 |
| normal_call.txt | 정상 | ✅ 정상 | 0.1669 | ✅ 정답 |

**정확도**: 75% (3/4)
**문제점**: complaint_call.txt 오탐 (불만 표현을 욕설로 오인)

### 현재 시스템의 한계

1. **Fine-tuning 미실시**
   - KcBERT가 댓글 데이터로만 사전학습됨
   - 통화 내용 특성 반영 안됨
   - classifier 레이어가 무작위 초기화 상태

2. **규칙 기반의 단순성**
   - 단순 키워드 매칭
   - 문맥 고려 안함
   - "답답하네", "짜증나" 같은 경계 표현 처리 어려움

3. **고정된 가중치**
   - 모델 점수 70% + 규칙 점수 30%
   - 상황에 따른 동적 조정 불가

4. **단일 임계값**
   - 0.5 고정
   - 파일 특성별 차별화 없음

---

## 🎯 개선 방안 (우선순위별)

### 1단계: 즉시 적용 가능 (코드 수정)

#### 1.1 규칙 기반 강화 ⭐⭐⭐⭐⭐
**난이도**: 낮음 | **효과**: 즉시 | **비용**: 무료

**개선 내용**:
- 욕설 사전 확장 (100개 → 500개)
- 문맥 기반 필터링 (부정어 + 욕설 조합)
- 강도별 욕설 분류 (경미/중간/심각)
- 화이트리스트 추가 ("답답하네" 등 경계 표현)

**예상 효과**: 정확도 75% → 85%

```python
# 강도별 욕설 분류
severe_words = ['씨발', '병신', '개새']  # 심각
moderate_words = ['짜증', '답답']        # 중간
context_words = ['죽이고 싶다', '때리고 싶다']  # 문맥 필요
```

#### 1.2 동적 임계값 조정 ⭐⭐⭐⭐
**난이도**: 낮음 | **효과**: 즉시 | **비용**: 무료

**개선 내용**:
- 텍스트 길이에 따른 임계값 조정
- 욕설 빈도에 따른 가중치 변경
- 신뢰도 기반 동적 임계값

**예상 효과**: 오탐률 25% → 15%

```python
# 동적 임계값
if rule_score > 0.7:  # 명확한 욕설 패턴
    threshold = 0.4    # 낮은 임계값
elif rule_score < 0.2:  # 욕설 패턴 없음
    threshold = 0.6    # 높은 임계값
```

#### 1.3 앙상블 방식 개선 ⭐⭐⭐
**난이도**: 중간 | **효과**: 중간 | **비용**: 무료

**개선 내용**:
- 신뢰도 기반 가중치 조정
- 규칙 점수와 모델 점수의 일치도 확인
- 불일치 시 보수적 판단

**예상 효과**: 정확도 85% → 88%

---

### 2단계: 단기 개선 (1-2주)

#### 2.1 데이터 증강 ⭐⭐⭐⭐⭐
**난이도**: 중간 | **효과**: 높음 | **비용**: 시간

**방법**:
1. 기존 샘플 변형
   - 동의어 치환
   - 문장 순서 변경
   - 욕설 강도 조정

2. 합성 데이터 생성
   - 템플릿 기반 생성
   - 욕설 + 정상 문장 조합

**예상 효과**: 
- 학습 데이터 10배 증가
- 다양성 향상

```python
# 예시
원본: "배송이 너무 느려요"
증강1: "배송이 정말 느리네요"
증강2: "배송 속도가 너무 느립니다"
```

#### 2.2 사전 학습 모델 비교 ⭐⭐⭐⭐
**난이도**: 중간 | **효과**: 높음 | **비용**: 무료

**테스트 모델**:
1. KcBERT (현재)
2. KoBERT
3. KoELECTRA
4. KcELECTRA

**방법**: 각 모델로 동일 테스트 수행 후 최적 모델 선택

#### 2.3 감정 분석 레이어 추가 ⭐⭐⭐
**난이도**: 중간 | **효과**: 중간 | **비용**: 무료

**개선 내용**:
- 감정 점수 추가 (부정/중립/긍정)
- 감정 + 욕설 종합 판단
- 불만 표현과 욕설 구분

---

### 3단계: 중기 개선 (1-2개월)

#### 3.1 Fine-tuning ⭐⭐⭐⭐⭐
**난이도**: 높음 | **효과**: 매우 높음 | **비용**: GPU 필요

**방법**:
1. 데이터 수집 (1000개 이상)
   - 실제 통화 내용
   - 공개 댓글 데이터셋
   - 크라우드소싱

2. 라벨링
   - 욕설/정상 이진 분류
   - 강도별 다중 분류

3. Fine-tuning
   - Learning rate: 2e-5
   - Epochs: 3-5
   - Batch size: 16

**예상 효과**: 정확도 88% → 95%+

**필요 리소스**:
- GPU: V100 또는 A100 (Colab Pro 가능)
- 시간: 2-4시간
- 비용: $10-50

#### 3.2 다중 작업 학습 (Multi-task) ⭐⭐⭐
**난이도**: 높음 | **효과**: 높음 | **비용**: GPU 필요

**작업**:
1. 욕설 감지 (주 작업)
2. 감정 분류 (보조 작업)
3. 의도 파악 (보조 작업)

**효과**: 문맥 이해도 향상

#### 3.3 Attention 시각화 ⭐⭐
**난이도**: 중간 | **효과**: 디버깅 | **비용**: 무료

**용도**:
- 모델이 주목하는 단어 확인
- 오탐/미탐 원인 분석
- 규칙 개선 아이디어 도출

---

### 4단계: 장기 개선 (3개월+)

#### 4.1 대규모 데이터셋 구축 ⭐⭐⭐⭐⭐
**난이도**: 매우 높음 | **효과**: 매우 높음 | **비용**: 높음

**목표**: 10,000개 이상의 라벨링된 통화 데이터

**방법**:
1. 실제 고객센터 데이터 수집
2. 크라우드소싱 라벨링
3. Active Learning (모델이 어려워하는 샘플 우선 라벨링)

#### 4.2 전용 모델 개발 ⭐⭐⭐⭐
**난이도**: 매우 높음 | **효과**: 최고 | **비용**: 매우 높음

**방법**:
- 처음부터 통화 데이터로 사전학습
- 도메인 특화 토크나이저
- 대화 구조 이해

#### 4.3 실시간 피드백 루프 ⭐⭐⭐
**난이도**: 높음 | **효과**: 지속적 개선 | **비용**: 시스템 구축

**시스템**:
1. 사용자 피드백 수집
2. 오탐/미탐 케이스 자동 수집
3. 주기적 재학습

---

## 🚀 즉시 구현 가능한 개선안 (코드)

### 개선 1: 강화된 규칙 기반

```python
class ImprovedAbusiveDetector:
    def __init__(self):
        # 강도별 욕설 분류
        self.severe_patterns = {
            '씨발', '시발', '병신', '개새끼', '좆', 
            '미친새끼', '니미', 'ㅅㅂ', 'ㅂㅅ'
        }
        
        self.moderate_patterns = {
            '짜증', '빡', '열받', '엿먹', '꺼져',
            '닥쳐', '죽이고', '때리고'
        }
        
        # 화이트리스트 (오탐 방지)
        self.whitelist = {
            '답답하네', '답답합니다', '아쉽네요',
            '안타깝', '불편', '개선'
        }
        
        # 문맥 욕설 (부정어와 함께 사용 시)
        self.context_patterns = {
            '죽': ['죽이고 싶', '죽겠'],
            '때리': ['때리고 싶', '때릴'],
        }
    
    def check_with_context(self, text):
        score = 0.0
        
        # 심각한 욕설 (가중치 높음)
        for pattern in self.severe_patterns:
            if pattern in text:
                score += 0.4
        
        # 중간 욕설 (가중치 중간)
        for pattern in self.moderate_patterns:
            if pattern in text:
                # 화이트리스트 체크
                if not any(w in text for w in self.whitelist):
                    score += 0.2
        
        # 문맥 욕설
        for base, contexts in self.context_patterns.items():
            if base in text:
                if any(ctx in text for ctx in contexts):
                    score += 0.3
        
        return min(score, 1.0)
```

### 개선 2: 동적 임계값

```python
def dynamic_threshold(self, text, rule_score, model_score, confidence):
    """상황에 따라 임계값을 동적으로 조정"""
    
    base_threshold = 0.5
    
    # 규칙 점수가 매우 높으면 임계값 낮춤 (민감)
    if rule_score > 0.7:
        threshold = 0.3
    
    # 규칙 점수가 매우 낮으면 임계값 높임 (보수적)
    elif rule_score < 0.1:
        threshold = 0.7
    
    # 신뢰도가 낮으면 보수적
    elif confidence < 0.6:
        threshold = 0.6
    
    else:
        threshold = base_threshold
    
    return threshold
```

### 개선 3: 스코어 보정

```python
def adjust_score(self, model_score, rule_score, confidence):
    """규칙과 모델의 일치도에 따라 점수 보정"""
    
    # 둘 다 높으면 확신 증가
    if model_score > 0.6 and rule_score > 0.6:
        return min(model_score * 1.2, 1.0)
    
    # 둘 다 낮으면 확신 증가 (정상)
    elif model_score < 0.3 and rule_score < 0.3:
        return model_score * 0.8
    
    # 불일치 시 보수적 (더 낮은 점수)
    elif abs(model_score - rule_score) > 0.4:
        return min(model_score, rule_score)
    
    # 기본: 가중 평균
    else:
        return model_score * 0.7 + rule_score * 0.3
```

---

## 📈 예상 개선 효과

| 단계 | 방법 | 정확도 | 구현 난이도 | 비용 |
|------|------|--------|------------|------|
| 현재 | 기본 시스템 | 75% | - | - |
| 1단계 | 규칙 강화 + 동적 임계값 | 85% | ⭐ | 무료 |
| 2단계 | + 데이터 증강 | 88% | ⭐⭐ | 무료 |
| 3단계 | + Fine-tuning | 95% | ⭐⭐⭐⭐ | $10-50 |
| 4단계 | + 대규모 데이터 | 98% | ⭐⭐⭐⭐⭐ | $1000+ |

---

## 💡 권장 로드맵

### Phase 1: 빠른 승리 (이번 주)
1. ✅ 규칙 기반 강화 구현
2. ✅ 동적 임계값 적용
3. ✅ 스코어 보정 로직 추가
4. ✅ 테스트 및 검증

### Phase 2: 데이터 준비 (다음 주)
1. 샘플 데이터 10개 → 100개 확장
2. 데이터 증강 스크립트 작성
3. 다양한 시나리오 추가

### Phase 3: 모델 개선 (한 달)
1. Fine-tuning 데이터셋 구축 (500-1000개)
2. Google Colab에서 Fine-tuning
3. 성능 비교 및 배포

### Phase 4: 지속 개선 (진행중)
1. 사용자 피드백 수집
2. 주기적 재학습
3. 새로운 욕설 패턴 추가

---

**작성일**: 2026-01-21  
**버전**: 1.0
