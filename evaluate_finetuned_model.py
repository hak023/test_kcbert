# -*- coding: utf-8 -*-
"""
Fine-tuned ëª¨ë¸ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
ì›ë³¸ KcBERT vs Fine-tuned KcBERT ì„±ëŠ¥ ë¹„êµ
"""

import sys
import os
import warnings
import time
from pathlib import Path
from datetime import datetime
import json

warnings.filterwarnings('ignore')
os.environ['TRANSFORMERS_VERBOSITY'] = 'error'

if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

import logging
logging.getLogger('transformers').setLevel(logging.ERROR)


def print_header(title):
    """í—¤ë” ì¶œë ¥"""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80 + "\n")


def classify_result(score, threshold=0.5):
    """ì ìˆ˜ë¡œ ë ˆì´ë¸” ë¶„ë¥˜"""
    if score < 0.3:
        return "ì •ìƒ"
    elif score < 0.6:
        return "ê²½ê³„ì„ "
    else:
        return "ë¶€ì ì ˆ"


def calculate_accuracy(predictions, ground_truth):
    """ì •í™•ë„ ê³„ì‚°"""
    correct = 0
    total = len(predictions)
    
    for filename, pred in predictions.items():
        if filename not in ground_truth:
            continue
        
        gt = ground_truth[filename]
        pred_label = classify_result(pred['score'])
        
        if pred_label == gt['label']:
            correct += 1
    
    return (correct / total * 100) if total > 0 else 0


def calculate_score_error(predictions, ground_truth):
    """í‰ê·  ì ìˆ˜ ì˜¤ì°¨ ê³„ì‚° (MAE)"""
    errors = []
    
    for filename, pred in predictions.items():
        if filename not in ground_truth:
            continue
        
        gt = ground_truth[filename]
        error = abs(pred['score'] - gt['score'])
        errors.append(error)
    
    return sum(errors) / len(errors) if errors else 0


# Ground Truth (ì‹¤ì œ ì •ë‹µ)
GROUND_TRUTH = {
    "test_01_normal_service.txt": {"label": "ì •ìƒ", "score": 0.1, "category": "ì—†ìŒ"},
    "test_02_strong_complaint.txt": {"label": "ê²½ê³„ì„ ", "score": 0.4, "category": "ë¶ˆë§Œ"},
    "test_03_explicit_profanity.txt": {"label": "ë¶€ì ì ˆ", "score": 0.95, "category": "ìš•ì„¤"},
    "test_04_insult_no_swear.txt": {"label": "ë¶€ì ì ˆ", "score": 0.85, "category": "ëª¨ìš•"},
    "test_05_direct_threat.txt": {"label": "ë¶€ì ì ˆ", "score": 0.9, "category": "ìœ„í˜‘"},
    "test_06_sexual_harassment_direct.txt": {"label": "ë¶€ì ì ˆ", "score": 0.95, "category": "ì„±í¬ë¡±"},
    "test_07_sexual_harassment_subtle.txt": {"label": "ë¶€ì ì ˆ", "score": 0.75, "category": "ì„±í¬ë¡±"},
    "test_08_sarcastic_insult.txt": {"label": "ë¶€ì ì ˆ", "score": 0.7, "category": "ëª¨ìš•"},
    "test_09_borderline_angry.txt": {"label": "ê²½ê³„ì„ ", "score": 0.45, "category": "ë¶ˆë§Œ"},
    "test_10_borderline_frustrated.txt": {"label": "ê²½ê³„ì„ ", "score": 0.5, "category": "ë¶ˆë§Œ"},
    "test_11_threat_legal.txt": {"label": "ê²½ê³„ì„ ", "score": 0.55, "category": "ìœ„í˜‘"},
    "test_12_mixed_profanity_threat.txt": {"label": "ë¶€ì ì ˆ", "score": 0.98, "category": "ë³µí•©"},
    "test_13_profanity_sexual.txt": {"label": "ë¶€ì ì ˆ", "score": 0.98, "category": "ë³µí•©"},
    "test_14_polite_complaint.txt": {"label": "ì •ìƒ", "score": 0.2, "category": "ì—†ìŒ"},
    "test_15_urgent_request.txt": {"label": "ì •ìƒ", "score": 0.1, "category": "ì—†ìŒ"},
    "test_16_passive_aggressive.txt": {"label": "ë¶€ì ì ˆ", "score": 0.65, "category": "ëª¨ìš•"},
    "test_17_mild_insult.txt": {"label": "ë¶€ì ì ˆ", "score": 0.6, "category": "ëª¨ìš•"},
    "test_18_explicit_threat.txt": {"label": "ë¶€ì ì ˆ", "score": 0.95, "category": "ìœ„í˜‘"},
    "test_19_emotional_outburst.txt": {"label": "ê²½ê³„ì„ ", "score": 0.5, "category": "ë¶ˆë§Œ"},
    "test_20_appreciation.txt": {"label": "ì •ìƒ", "score": 0.0, "category": "ì—†ìŒ"},
}


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print_header("ğŸ”¬ Fine-tuned ëª¨ë¸ í‰ê°€")
    
    print("ğŸ“ í‰ê°€ ê°œìš”")
    print("-" * 80)
    print("  â”œâ”€ ì›ë³¸ KcBERT vs Fine-tuned KcBERT")
    print("  â”œâ”€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: 20ê°œ")
    print("  â””â”€ í‰ê°€ ì§€í‘œ: ì •í™•ë„, MAE")
    print()
    
    # Fine-tuned ëª¨ë¸ í™•ì¸
    finetuned_model_path = "models/kcbert-finetuned-issue-cases"
    if not os.path.exists(finetuned_model_path):
        print(f"âŒ Fine-tuned ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {finetuned_model_path}")
        print("   ë¨¼ì € 'python finetune_issue_cases.py'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    print(f"âœ… Fine-tuned ëª¨ë¸ ë°œê²¬: {finetuned_model_path}")
    print()
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ í™•ì¸
    samples_dir = Path("data/samples")
    test_files = sorted([f for f in samples_dir.glob("test_*.txt")])
    
    if not test_files:
        print("âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… í…ŒìŠ¤íŠ¸ íŒŒì¼ {len(test_files)}ê°œ ë°œê²¬")
    print()
    
    # ëª¨ë¸ ë¡œë”©
    print_header("1ï¸âƒ£ ì›ë³¸ KcBERT ëª¨ë¸ ë¡œë”©")
    from src.detector_multi import MultiCategoryDetector
    
    original_detector = MultiCategoryDetector()
    print("âœ… ì›ë³¸ ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    
    print_header("2ï¸âƒ£ Fine-tuned KcBERT ëª¨ë¸ ë¡œë”©")
    
    # Fine-tuned ëª¨ë¸ ë¡œë” (ì„ì‹œë¡œ ì›ë³¸ ì‚¬ìš©, ëª¨ë¸ ê²½ë¡œë§Œ ë³€ê²½)
    import torch
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
    
    tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path)
    model = AutoModelForSequenceClassification.from_pretrained(
        finetuned_model_path,
        ignore_mismatched_sizes=True
    )
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    model.eval()
    
    print("âœ… Fine-tuned ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    print()
    
    # ì›Œë°ì—… ì‹¤í–‰ (ëª¨ë¸ ì´ˆê¸°í™” ì‹œê°„ ì œì™¸)
    print_header("2.5ï¸âƒ£ ëª¨ë¸ ì›Œë°ì—…")
    print("â³ ëª¨ë¸ ì›Œë°ì—… ì¤‘... (ì²« ì¼€ì´ìŠ¤ ì²˜ë¦¬ ì‹œê°„ ë³´ì •ì„ ìœ„í•¨)")
    print()
    
    warmup_text = "ì•ˆë…•í•˜ì„¸ìš”. í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤."
    
    print("  ğŸ”µ ì›ë³¸ KcBERT ì›Œë°ì—…...", end=" ", flush=True)
    _ = original_detector.predict(warmup_text)
    print("ì™„ë£Œ")
    
    print("  ğŸŸ¢ Fine-tuned KcBERT ì›Œë°ì—…...", end=" ", flush=True)
    warmup_inputs = tokenizer(
        warmup_text,
        add_special_tokens=True,
        max_length=300,
        padding='max_length',
        truncation=True,
        return_tensors='pt'
    ).to(device)
    
    with torch.no_grad():
        _ = model(**warmup_inputs)
    print("ì™„ë£Œ")
    
    print()
    print("âœ… ì›Œë°ì—… ì™„ë£Œ! ì´ì œ ì •í™•í•œ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print_header("3ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    
    original_results = {}
    finetuned_results = {}
    
    original_total_time = 0
    finetuned_total_time = 0
    
    for i, test_file in enumerate(test_files, 1):
        filename = test_file.name
        print(f"[{i}/{len(test_files)}] {filename}")
        print("-" * 80)
        
        # íŒŒì¼ ì½ê¸°
        with open(test_file, 'r', encoding='utf-8') as f:
            text = f.read().strip()
        
        print(f"ğŸ“ ë‚´ìš©: \"{text[:50]}{'...' if len(text) > 50 else ''}\"")
        print()
        
        # ì›ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸
        print("  ğŸ”µ ì›ë³¸ KcBERT ë¶„ì„ ì¤‘...", end=" ", flush=True)
        start_time = time.time()
        original_result = original_detector.predict(text)
        original_time = time.time() - start_time
        original_total_time += original_time
        
        print(f"ì™„ë£Œ ({original_time:.2f}ì´ˆ)")
        print(f"     ì ìˆ˜: {original_result['abusive_score']:.3f}")
        print(f"     íŒì •: {'ë¶€ì ì ˆ' if original_result['is_abusive'] else 'ì •ìƒ'}")
        print()
        
        original_results[filename] = {
            'score': original_result['abusive_score'],
            'is_abusive': original_result['is_abusive'],
            'time': original_time
        }
        
        # Fine-tuned ëª¨ë¸ í…ŒìŠ¤íŠ¸
        print("  ğŸŸ¢ Fine-tuned KcBERT ë¶„ì„ ì¤‘...", end=" ", flush=True)
        start_time = time.time()
        
        # í† í°í™”
        inputs = tokenizer(
            text,
            add_special_tokens=True,
            max_length=300,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        ).to(device)
        
        # ì¶”ë¡ 
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=1)
            score = probs[0][1].item()  # ë¶€ì ì ˆ í™•ë¥ 
            is_abusive = score >= 0.5
        
        finetuned_time = time.time() - start_time
        finetuned_total_time += finetuned_time
        
        print(f"ì™„ë£Œ ({finetuned_time:.2f}ì´ˆ)")
        print(f"     ì ìˆ˜: {score:.3f}")
        print(f"     íŒì •: {'ë¶€ì ì ˆ' if is_abusive else 'ì •ìƒ'}")
        print()
        
        finetuned_results[filename] = {
            'score': score,
            'is_abusive': is_abusive,
            'time': finetuned_time
        }
        
        print()
    
    # í†µê³„ ê³„ì‚°
    print_header("4ï¸âƒ£ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
    
    # ì •í™•ë„
    original_accuracy = calculate_accuracy(original_results, GROUND_TRUTH)
    finetuned_accuracy = calculate_accuracy(finetuned_results, GROUND_TRUTH)
    
    # ì ìˆ˜ ì˜¤ì°¨
    original_mae = calculate_score_error(original_results, GROUND_TRUTH)
    finetuned_mae = calculate_score_error(finetuned_results, GROUND_TRUTH)
    
    # í‰ê·  ì²˜ë¦¬ ì‹œê°„
    original_avg_time = original_total_time / len(test_files)
    finetuned_avg_time = finetuned_total_time / len(test_files)
    
    print("ğŸ“Š ì „ì²´ í†µê³„")
    print("-" * 80)
    print()
    
    print("  â±ï¸  ì²˜ë¦¬ ì‹œê°„ ë¹„êµ")
    print(f"     ì›ë³¸:      {original_total_time:.2f}ì´ˆ (í‰ê·  {original_avg_time:.2f}ì´ˆ/ê±´)")
    print(f"     Fine-tuned: {finetuned_total_time:.2f}ì´ˆ (í‰ê·  {finetuned_avg_time:.2f}ì´ˆ/ê±´)")
    improvement = ((finetuned_avg_time - original_avg_time) / original_avg_time) * 100
    print(f"     ë³€í™”:      {improvement:+.1f}%")
    print()
    
    print("  ğŸ¯ ì •í™•ë„ ë¹„êµ")
    print(f"     ì›ë³¸:      {original_accuracy:.1f}%")
    print(f"     Fine-tuned: {finetuned_accuracy:.1f}%")
    accuracy_improvement = finetuned_accuracy - original_accuracy
    print(f"     ê°œì„ :      {accuracy_improvement:+.1f}%p {'âœ…' if accuracy_improvement > 0 else 'âš ï¸'}")
    print()
    
    print("  ğŸ“ ì ìˆ˜ ì˜¤ì°¨ (MAE)")
    print(f"     ì›ë³¸:      {original_mae:.3f}")
    print(f"     Fine-tuned: {finetuned_mae:.3f}")
    mae_improvement = original_mae - finetuned_mae
    print(f"     ê°œì„ :      {mae_improvement:+.3f} {'âœ…' if mae_improvement > 0 else 'âš ï¸'}")
    print()
    
    # ìƒì„¸ ë¹„êµí‘œ
    print_header("5ï¸âƒ£ ìƒì„¸ ë¹„êµí‘œ")
    
    print(f"{'íŒŒì¼ëª…':<35} | {'ì‹¤ì œ':^8} | {'ì›ë³¸':^8} | {'Fine-tuned':^8} | {'ê°œì„ ':^8}")
    print("-" * 80)
    
    improvement_count = 0
    for filename in sorted(test_files, key=lambda x: x.name):
        fn = filename.name
        gt = GROUND_TRUTH.get(fn, {})
        orig = original_results.get(fn, {})
        fine = finetuned_results.get(fn, {})
        
        gt_score = gt.get('score', 0)
        orig_score = orig.get('score', 0)
        fine_score = fine.get('score', 0)
        
        # ê°œì„  ì—¬ë¶€ íŒë‹¨
        orig_error = abs(orig_score - gt_score)
        fine_error = abs(fine_score - gt_score)
        improved = "âœ…" if fine_error < orig_error else ("âš ï¸" if fine_error > orig_error else "â–")
        
        if fine_error < orig_error:
            improvement_count += 1
        
        print(f"{fn:<35} | {gt_score:>6.2f}  | {orig_score:>6.3f}  | {fine_score:>6.3f}  | {improved:^8}")
    
    print()
    print(f"  ê°œì„ ëœ ì¼€ì´ìŠ¤: {improvement_count}/{len(test_files)} ({improvement_count/len(test_files)*100:.1f}%)")
    print()
    
    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_file = f"data/results/finetuned_evaluation_{timestamp}.json"
    
    evaluation_result = {
        "timestamp": timestamp,
        "test_count": len(test_files),
        "summary": {
            "original": {
                "total_time": original_total_time,
                "avg_time": original_avg_time,
                "accuracy": original_accuracy,
                "mae": original_mae
            },
            "finetuned": {
                "total_time": finetuned_total_time,
                "avg_time": finetuned_avg_time,
                "accuracy": finetuned_accuracy,
                "mae": finetuned_mae
            },
            "improvement": {
                "accuracy": accuracy_improvement,
                "mae": mae_improvement,
                "improved_cases": improvement_count,
                "improved_percentage": improvement_count / len(test_files) * 100
            }
        },
        "original_results": original_results,
        "finetuned_results": finetuned_results,
        "ground_truth": GROUND_TRUTH
    }
    
    os.makedirs("data/results", exist_ok=True)
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(evaluation_result, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {result_file}")
    print()
    
    # ìµœì¢… ê²°ë¡ 
    print_header("6ï¸âƒ£ ìµœì¢… ê²°ë¡ ")
    
    print("ğŸ† ì¢…í•© í‰ê°€")
    print("-" * 80)
    print()
    
    if accuracy_improvement > 10:
        print("  âœ… ìš°ìˆ˜: Fine-tuningì´ ë§¤ìš° íš¨ê³¼ì ì´ì—ˆìŠµë‹ˆë‹¤!")
        print(f"     ì •í™•ë„ê°€ {accuracy_improvement:.1f}%p í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.")
    elif accuracy_improvement > 0:
        print("  âš ï¸  ì–‘í˜¸: Fine-tuningì´ ì–´ëŠ ì •ë„ íš¨ê³¼ê°€ ìˆì—ˆìŠµë‹ˆë‹¤.")
        print(f"     ì •í™•ë„ê°€ {accuracy_improvement:.1f}%p í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("  âŒ ë¯¸í¡: Fine-tuning íš¨ê³¼ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        print("     ë” ë§ì€ í•™ìŠµ ë°ì´í„°ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    print()
    
    if mae_improvement > 0.05:
        print("  âœ… ì ìˆ˜ ì •í™•ì„±ë„ í¬ê²Œ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤!")
    elif mae_improvement > 0:
        print("  âš ï¸  ì ìˆ˜ ì •í™•ì„±ì´ ì•½ê°„ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("  âŒ ì ìˆ˜ ì •í™•ì„± ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    print()
    print("=" * 80)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
