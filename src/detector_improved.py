"""
ê°œì„ ëœ ìš•ì„¤/í­ì–¸ ê°ì§€ ì—”ì§„ - ì •í™•ë„ í–¥ìƒ ë²„ì „
"""

import time
import torch
import numpy as np
from typing import Dict, List, Any
from .model_loader import ModelLoader


class ImprovedAbusiveDetector:
    """ê°œì„ ëœ KcBERT ê¸°ë°˜ ìš•ì„¤/í­ì–¸ ê°ì§€ ì—”ì§„"""
    
    def __init__(self,
                 model_name: str = "beomi/kcbert-base",
                 cache_dir: str = "./models/kcbert",
                 threshold: float = 0.5,
                 max_length: int = 300,
                 use_dynamic_threshold: bool = True):
        """
        Args:
            model_name: ëª¨ë¸ëª…
            cache_dir: ìºì‹œ ë””ë ‰í† ë¦¬
            threshold: ê¸°ë³¸ ê°ì§€ ì„ê³„ê°’ (ë™ì  ì„ê³„ê°’ ì‚¬ìš© ì‹œ ê¸°ì¤€ê°’)
            max_length: ìµœëŒ€ í† í° ê¸¸ì´
            use_dynamic_threshold: ë™ì  ì„ê³„ê°’ ì‚¬ìš© ì—¬ë¶€
        """
        self.base_threshold = threshold
        self.max_length = max_length
        self.use_dynamic_threshold = use_dynamic_threshold
        
        # ëª¨ë¸ ë¡œë” ì´ˆê¸°í™”
        self.loader = ModelLoader(
            model_name=model_name,
            cache_dir=cache_dir
        )
        
        self.tokenizer = None
        self.model = None
        self.device = None
        
        # ê°•ë„ë³„ ìš•ì„¤ íŒ¨í„´
        self.severe_patterns = {
            'ì”¨ë°œ', 'ì‹œë°œ', 'ã……ã…‚', 'ë³‘ì‹ ', 'ã…‚ã……', 'ê°œìƒˆ', 'ê°œìƒˆë¼',
            'ì¢†', 'ì¢ƒ', 'ë‹ˆë¯¸', 'ë‹ˆì—„ë§ˆ', 'ì—¿ë¨¹', 'ê°œê°™', 'ê°œ ê°™',
            'ë¯¸ì¹œìƒˆë¼', 'ë¯¸ì¹œë†ˆ', 'ë¯¸ì¹œë…„', 'ì§€ë„', 'ì—¼ë³‘', 'ì…',
            'ê°œìì‹', 'ê°œë…„', 'ê°œë†ˆ', 'ì“°ë ˆê¸°ìƒˆë¼', 'ì¸ê°„ì“°ë ˆê¸°'
        }
        
        self.moderate_patterns = {
            'ì§œì¦', 'ë¹¡', 'ì—´ë°›', 'êº¼ì ¸', 'ë‹¥ì³', 'ì—¿ê°™',
            'ì£½ì´ê³  ì‹¶', 'ë•Œë¦¬ê³  ì‹¶', 'ì‘ì‚´', 'ê°œë¹¡', 
            'ë¯¸ì¹œ', 'ë¯¸ì³¤', 'ëŒì•˜', 'ëŒì•„ë²„'
        }
        
        # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ (ì •ìƒ í‘œí˜„)
        self.whitelist_patterns = {
            'ë‹µë‹µí•˜', 'ë‹µë‹µí•©ë‹ˆë‹¤', 'ì•„ì‰½', 'ì•ˆíƒ€ê¹', 
            'ë¶ˆí¸', 'ê°œì„ ', 'ë¯¸ì¹œë“¯ì´ ì¢‹', 'ë¯¸ì¹œë“¯ì´ ë¹ ë¥¸',
            'ì£½ì´ëŠ” ë§›', 'ì£½ì´ëŠ” ë””ìì¸'
        }
        
        # ë¬¸ë§¥ í‚¤ì›Œë“œ (ë¬¸ì¥ ì „ì²´ë¥¼ ë´ì•¼ í•˜ëŠ” ê²½ìš°)
        self.context_negative = {
            'ë‹µë‹µ': ['ì •ë§ ë‹µë‹µ', 'ë„ˆë¬´ ë‹µë‹µ', 'ë‹µë‹µí•´ ì£½'],
            'ë¯¸ì¹œ': ['ë¯¸ì¹œë†ˆ', 'ë¯¸ì¹œìƒˆë¼', 'ë¯¸ì³¤ì–´'],
        }
    
    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        if self.model is None:
            print("\n" + "="*60)
            print("ğŸ¤– KcBERT ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
            print("="*60 + "\n")
            
            self.tokenizer, self.model = self.loader.load()
            self.device = self.loader.get_device()
            
            print("\n" + "="*60)
            print("âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!")
            print("="*60 + "\n")
    
    def _check_whitelist(self, text: str) -> bool:
        """í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì²´í¬ (ì •ìƒ í‘œí˜„ì¸ì§€)"""
        text_lower = text.lower()
        return any(pattern in text_lower for pattern in self.whitelist_patterns)
    
    def _check_context_negative(self, text: str, keyword: str) -> bool:
        """ë¬¸ë§¥ìƒ ë¶€ì •ì ì¸ì§€ í™•ì¸"""
        if keyword not in self.context_negative:
            return False
        
        text_lower = text.lower()
        return any(pattern in text_lower for pattern in self.context_negative[keyword])
    
    def _check_rule_based_advanced(self, text: str) -> Dict[str, Any]:
        """
        ê³ ê¸‰ ê·œì¹™ ê¸°ë°˜ ìš•ì„¤ ì²´í¬
        
        Returns:
            {
                'score': float,  # 0.0 ~ 1.0
                'severe_count': int,
                'moderate_count': int,
                'is_whitelist': bool
            }
        """
        text_lower = text.lower()
        
        # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì²´í¬
        if self._check_whitelist(text):
            return {
                'score': 0.0,
                'severe_count': 0,
                'moderate_count': 0,
                'is_whitelist': True
            }
        
        severe_count = 0
        moderate_count = 0
        
        # ì‹¬ê°í•œ ìš•ì„¤ ì²´í¬
        for pattern in self.severe_patterns:
            if pattern in text_lower:
                severe_count += 1
        
        # ì¤‘ê°„ ìš•ì„¤ ì²´í¬ (ë¬¸ë§¥ ê³ ë ¤)
        for pattern in self.moderate_patterns:
            if pattern in text_lower:
                # ë¬¸ë§¥ í™•ì¸
                base_keyword = pattern.split()[0] if ' ' in pattern else pattern
                if base_keyword in self.context_negative:
                    if self._check_context_negative(text, base_keyword):
                        moderate_count += 1
                else:
                    moderate_count += 1
        
        # ì ìˆ˜ ê³„ì‚°
        # ì‹¬ê°í•œ ìš•ì„¤: ê°œë‹¹ 0.5ì 
        # ì¤‘ê°„ ìš•ì„¤: ê°œë‹¹ 0.25ì 
        score = min(severe_count * 0.5 + moderate_count * 0.25, 1.0)
        
        return {
            'score': score,
            'severe_count': severe_count,
            'moderate_count': moderate_count,
            'is_whitelist': False
        }
    
    def _calculate_dynamic_threshold(self, 
                                    rule_score: float, 
                                    model_score: float,
                                    confidence: float,
                                    rule_info: Dict) -> float:
        """
        ë™ì  ì„ê³„ê°’ ê³„ì‚°
        """
        if not self.use_dynamic_threshold:
            return self.base_threshold
        
        threshold = self.base_threshold
        
        # ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ê°€ ë§¤ìš° ë†’ìœ¼ë©´ (ëª…í™•í•œ ìš•ì„¤)
        if rule_score >= 0.8:
            threshold = 0.35  # ë‚®ì€ ì„ê³„ê°’ (ë¯¼ê°í•˜ê²Œ)
        
        # ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ê°€ ë†’ìœ¼ë©´
        elif rule_score >= 0.5:
            threshold = 0.4
        
        # ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ê°€ ë§¤ìš° ë‚®ìœ¼ë©´ (ìš•ì„¤ íŒ¨í„´ ì—†ìŒ)
        elif rule_score < 0.1:
            threshold = 0.65  # ë†’ì€ ì„ê³„ê°’ (ë³´ìˆ˜ì ìœ¼ë¡œ)
        
        # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
        elif rule_info.get('is_whitelist'):
            threshold = 0.75  # ë§¤ìš° ë†’ì€ ì„ê³„ê°’
        
        # ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²½ìš° ë³´ìˆ˜ì ìœ¼ë¡œ
        if confidence < 0.6:
            threshold += 0.1
        
        return min(threshold, 0.9)  # ìµœëŒ€ 0.9
    
    def _adjust_final_score(self,
                           model_score: float,
                           rule_score: float,
                           confidence: float,
                           rule_info: Dict) -> float:
        """
        ìµœì¢… ì ìˆ˜ ë³´ì •
        """
        # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì ìˆ˜ ëŒ€í­ ê°ì†Œ
        if rule_info.get('is_whitelist'):
            return model_score * 0.3
        
        # ì‹¬ê°í•œ ìš•ì„¤ì´ ìˆëŠ” ê²½ìš°
        if rule_info['severe_count'] >= 2:
            # ê·œì¹™ ì ìˆ˜ë¥¼ ë” ë†’ê²Œ ë°˜ì˜
            return model_score * 0.5 + rule_score * 0.5
        
        elif rule_info['severe_count'] >= 1:
            return model_score * 0.6 + rule_score * 0.4
        
        # ê·œì¹™ê³¼ ëª¨ë¸ì´ ì¼ì¹˜í•˜ëŠ” ê²½ìš° (ë‘˜ ë‹¤ ë†’ìŒ)
        if model_score > 0.6 and rule_score > 0.6:
            # í™•ì‹  ì¦ê°€
            return min((model_score + rule_score) / 2 * 1.15, 1.0)
        
        # ê·œì¹™ê³¼ ëª¨ë¸ì´ ì¼ì¹˜í•˜ëŠ” ê²½ìš° (ë‘˜ ë‹¤ ë‚®ìŒ)
        elif model_score < 0.3 and rule_score < 0.3:
            # ì •ìƒì¼ í™•ë¥  ë†’ìŒ
            return (model_score + rule_score) / 2 * 0.85
        
        # ë¶ˆì¼ì¹˜ê°€ í° ê²½ìš°
        elif abs(model_score - rule_score) > 0.5:
            # ë³´ìˆ˜ì ìœ¼ë¡œ (ë‚®ì€ ìª½ ì„ íƒ)
            return min(model_score, rule_score) * 1.1
        
        # ê¸°ë³¸: ê°€ì¤‘ í‰ê· 
        # ê·œì¹™ ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ê·œì¹™ì˜ ê°€ì¤‘ì¹˜ ì¦ê°€
        rule_weight = 0.3 + (rule_score * 0.2)  # 0.3 ~ 0.5
        model_weight = 1.0 - rule_weight
        
        return model_score * model_weight + rule_score * rule_weight
    
    def predict(self, text: str) -> Dict[str, Any]:
        """
        ê°œì„ ëœ ë‹¨ì¼ í…ìŠ¤íŠ¸ ì˜ˆì¸¡
        """
        # ëª¨ë¸ ë¡œë“œ
        if self.model is None:
            self.load_model()
        
        start_time = time.time()
        
        # 1. ê³ ê¸‰ ê·œì¹™ ê¸°ë°˜ ì²´í¬
        rule_info = self._check_rule_based_advanced(text)
        rule_score = rule_info['score']
        
        # 2. ëª¨ë¸ ì˜ˆì¸¡
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            max_length=self.max_length,
            padding="max_length",
            truncation=True
        )
        
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits
            probabilities = torch.nn.functional.softmax(logits, dim=-1)
            abusive_prob = probabilities[0][1].item()
            confidence = torch.max(probabilities).item()
        
        # 3. ìµœì¢… ì ìˆ˜ ê³„ì‚°
        final_score = self._adjust_final_score(
            abusive_prob, rule_score, confidence, rule_info
        )
        
        # 4. ë™ì  ì„ê³„ê°’ ê³„ì‚°
        threshold = self._calculate_dynamic_threshold(
            rule_score, abusive_prob, confidence, rule_info
        )
        
        # 5. ì²˜ë¦¬ ì‹œê°„
        processing_time = time.time() - start_time
        
        # 6. ê²°ê³¼ êµ¬ì„±
        result = {
            "text": text,
            "is_abusive": final_score >= threshold,
            "confidence": confidence,
            "abusive_score": final_score,
            "model_score": abusive_prob,
            "rule_score": rule_score,
            "threshold": threshold,
            "processing_time": processing_time,
            "details": {
                "severe_words": rule_info['severe_count'],
                "moderate_words": rule_info['moderate_count'],
                "is_whitelist": rule_info['is_whitelist'],
                "dynamic_threshold_used": self.use_dynamic_threshold
            }
        }
        
        return result
    
    def predict_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ì˜ˆì¸¡"""
        results = []
        for text in texts:
            result = self.predict(text)
            results.append(result)
        return results
    
    def predict_file(self, filepath: str) -> Dict[str, Any]:
        """íŒŒì¼ì—ì„œ ì½ì–´ì„œ ì˜ˆì¸¡"""
        from .preprocessor import TextPreprocessor
        
        preprocessor = TextPreprocessor()
        text = preprocessor.preprocess_file(filepath)
        
        result = self.predict(text)
        result["source_file"] = filepath
        
        return result
