"""
KcBERT ëª¨ë¸ ë¡œë” ëª¨ë“ˆ
"""

import os
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from typing import Tuple


class ModelLoader:
    """KcBERT ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”"""
    
    def __init__(self, 
                 model_name: str = "beomi/kcbert-base",
                 cache_dir: str = "./models/kcbert",
                 device: str = None):
        """
        Args:
            model_name: Hugging Face ëª¨ë¸ëª…
            cache_dir: ëª¨ë¸ ìºì‹œ ë””ë ‰í† ë¦¬
            device: ì‹¤í–‰ ë””ë°”ì´ìŠ¤ ('cuda', 'cpu', None=ìë™ê°ì§€)
        """
        self.model_name = model_name
        self.cache_dir = cache_dir
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if device is None:
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = device
        
        # ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.cache_dir, exist_ok=True)
        
        self.tokenizer = None
        self.model = None
    
    def load_tokenizer(self) -> AutoTokenizer:
        """
        í† í¬ë‚˜ì´ì € ë¡œë“œ
        
        Returns:
            KcBERT í† í¬ë‚˜ì´ì €
        """
        if self.tokenizer is None:
            print(f"ğŸ“¥ í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘: {self.model_name}")
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_name,
                cache_dir=self.cache_dir
            )
            print(f"âœ“ í† í¬ë‚˜ì´ì € ë¡œë”© ì™„ë£Œ")
        
        return self.tokenizer
    
    def load_model(self) -> AutoModelForSequenceClassification:
        """
        ëª¨ë¸ ë¡œë“œ
        
        Returns:
            KcBERT ëª¨ë¸
        """
        if self.model is None:
            print(f"ğŸ“¥ ëª¨ë¸ ë¡œë”© ì¤‘: {self.model_name}")
            print(f"   ë””ë°”ì´ìŠ¤: {self.device}")
            
            # KcBERTëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ì „í•™ìŠµë§Œ ëœ ìƒíƒœ
            # ì‹¤ì œë¡œëŠ” ìš•ì„¤ ê°ì§€ìš©ìœ¼ë¡œ fine-tuningëœ ëª¨ë¸ì´ í•„ìš”í•˜ì§€ë§Œ,
            # ì—¬ê¸°ì„œëŠ” ë§ˆìŠ¤í¬ë“œ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ê³µê²©ì„±ì„ ì¶”ì •
            
            # ì°¸ê³ : ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” fine-tuningëœ ëª¨ë¸ ì‚¬ìš© í•„ìš”
            try:
                from transformers import BertForSequenceClassification, BertConfig
                
                # KcBERTì˜ ì„¤ì •ì„ ë¡œë“œ
                config = BertConfig.from_pretrained(
                    self.model_name,
                    cache_dir=self.cache_dir
                )
                
                # ë¶„ë¥˜ ë ˆì´ì–´ ì¶”ê°€
                config.num_labels = 2
                
                # ëª¨ë¸ ë¡œë“œ (ignore_mismatched_sizesë¡œ í¬ê¸° ë¶ˆì¼ì¹˜ ë¬´ì‹œ)
                self.model = BertForSequenceClassification.from_pretrained(
                    self.model_name,
                    config=config,
                    cache_dir=self.cache_dir,
                    ignore_mismatched_sizes=True  # í¬ê¸° ë¶ˆì¼ì¹˜ ë¬´ì‹œ
                )
                
                print("   âš ï¸  ê¸°ë³¸ KcBERT ì‚¬ìš© (fine-tuning ì•ˆë¨)")
                print("   ğŸ’¡ ì‹¤ì œ ì‚¬ìš©ì„ ìœ„í•´ì„œëŠ” ìš•ì„¤ ë°ì´í„°ë¡œ fine-tuning í•„ìš”")
                
            except Exception as e:
                print(f"   âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                raise
            
            self.model.to(self.device)
            self.model.eval()
            
            print(f"âœ“ ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        return self.model
    
    def load(self) -> Tuple[AutoTokenizer, AutoModelForSequenceClassification]:
        """
        í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë™ì‹œ ë¡œë“œ
        
        Returns:
            (í† í¬ë‚˜ì´ì €, ëª¨ë¸) íŠœí”Œ
        """
        tokenizer = self.load_tokenizer()
        model = self.load_model()
        
        return tokenizer, model
    
    def get_device(self) -> str:
        """í˜„ì¬ ë””ë°”ì´ìŠ¤ ë°˜í™˜"""
        return self.device
